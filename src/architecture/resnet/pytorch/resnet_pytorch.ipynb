{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "L-ss184rfDO9"
   },
   "source": [
    "# I) Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- We are going to have an in-depth review of [Deep Residual Learning for Image Recognition](https://arxiv.org/pdf/1512.03385.pdf) and [Study of Residual Networks for Image Recognition](https://arxiv.org/pdf/1805.00325.pdf) paper which introduces the ResNet architecture.\n",
    "- It's important to understand that the main problem here is the difficulty to optimize a deep network rather than its lack of ability to learn features.\n",
    "    - Feature learning (or representation learning) is the ability to find a transformation that maps raw data into a representation that is more suitable for a machine learning task (e.g classification)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Problem\n",
    "\n",
    "- Intuitively, the more layers we have, the better the accuracy will be.\n",
    "- So if we take a shallow network that performs well and copy its layers and stack them to make the model deeper, we can expect the deep network to perform comparably good or better than its counterpart.\n",
    "- Surprisingly, as we go deeper, accuracy increases up to a saturation point and then begins to degrade.\n",
    "- Unexpectedly, such degradation is not caused by overfitting and making the network even deeper leads to a high training error.\n",
    "- Here is an example on CIFAR-10.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/705017447169654814/unknown.png\">\n",
    "    <figcaption> Figure: Trained on CIFAR-10</figcaption>\n",
    "</div>\n",
    "\n",
    "<br>\n",
    "\n",
    "- Thus, the deep network performs worse than the shallow network.\n",
    "- One possible explanation could be that the deep network suffered from the vanishing gradient problem.\n",
    "- However, it can mostly be fixed with batch normalization and normalized initializations.\n",
    "- A second explanation could be that the deep network wasn't able to learn the identity function.\n",
    "    - Indeed, it could at least perform exactly like the shallow network by just \"learning nothing\" (remember the deep network was built by copying and stacking layers of the shallow network).\n",
    "    - But the fact that he wasn't able to perform exactly like the shallow network means he has trouble to learn nothing! (learn the identity function).\n",
    "- This suggest a new problem: **Is learning better networks as easy as stacking more layers ?**\n",
    "\n",
    "## Solution\n",
    "\n",
    "The solution to this problem is to use a **Residual module** so that adding more layer will not cause any performance degradation.\n",
    "\n",
    "A residual module is composed of:\n",
    "- a sequence of convolutions, batch normalization and ReLU activations.\n",
    "- a residual connection $x$.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/699941791360745512/unknown.png\">\n",
    "    <figcaption > Figure: Residual module</figcaption>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "- We then combine through addition the residual connection with the sequence.\n",
    "- Suppose $H(x) = F(x) + x$. If the deep network wants to learn the idendity function, it just has to use the residual connection and thus, set $F(x)$ to 0 !\n",
    "- It is always easier for a sequence of layer to fit to a zero than an identity function, so the proposed structure is easier to train and ensure that a deeper network will be at least comparably good or better than its counterpart (**neutral-or-better characteristic**).\n",
    "- The residual connection is also called **skip connection** because they give a chance for the information to skip the function located within the residual module.\n",
    "- **Skip connection** provides a clear path for gradients to back propagate to early layers of the network. This makes the learning process faster by avoiding vanishing gradient problem.\n",
    "- However, the trade of is that residual networks are more prone to overfitting.\n",
    "- It seems that residual modules are more powerful for very deep networks and could even hurt the performance for very shallow networks if employed improperly.\n",
    "- When several residual modules are stacked, residual networks can be thought of as a complex combinations or ensemble of many shallower networks.\n",
    "\n",
    "<div style=\"text-align:center\">\n",
    "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/702786810186825778/unknown.png\">\n",
    "    <figcaption > Figure: Residual module</figcaption>\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "## Architecture\n",
    "\n",
    "There are several types of ResNet-X (with X, the number of layers).\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/703518172124545084/unknown.png\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "- For ResNet-50/101/152, they used a bottleneck architecture because they are cheaper in term of operations.\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/703528990316691466/unknown.png\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "- We are going to implement ResNet on CIFAR-10 which architecture is slighty different from the ImageNet one (probably due to its input image size).\n",
    "- Here is the ResNet-50 architecture on Imagenet:\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/704607455979634688/unknown.png\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/704624182289367040/unknown.png\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/704624228334305382/unknown.png\" width=\"50%\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "- We use identity shortcuts when input and output channel dimensions are the same.\n",
    "- Otherwise, we have 2 options:\n",
    "    - A) Use identity shortcuts with zero padding to increase channel dimension.\n",
    "    - B) Use 1x1 convolution to increase channel dimension (projection shortcut).\n",
    "- When input and output spatial dimensions don't match, we use one of the 2 above options with stride 2.\n",
    "- Since we are going to implemenet ResNet-50 on CIFAR-10, the architecture will be slightly different (ResNet-56):\n",
    "    - No maxpooling (probably due to small input size).\n",
    "    - We will use option A)\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/704999521608007680/unknown.png\">\n",
    "</div>\n",
    "<br>\n",
    "\n",
    "<div style=\"text-align: center\">\n",
    "    <img src=\"https://cdn.discordapp.com/attachments/676833120053493770/704626011412627536/unknown.png\" width=\"50%\">\n",
    "</div>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "vCeJmMDmfDPU"
   },
   "source": [
    "# II) Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "fqs_B60VfDPc"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "from collections import OrderedDict\n",
    "from IPython.display import clear_output\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torchvision import transforms, datasets\n",
    "from torchsummary import summary\n",
    "from torch.utils.data import Dataset, DataLoader, random_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "DezKkNaCfKX3"
   },
   "source": [
    "## a) Loading dataset / Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "uLmbAySUfP-K"
   },
   "outputs": [],
   "source": [
    "def load_cifar():\n",
    "    transform = transforms.Compose([transforms.ToTensor(),\n",
    "                                    transforms.Normalize(mean=[0.5], std=[0.5])])\n",
    "            \n",
    "    train_dataset = datasets.CIFAR10('./data', train=True, download=True, transform=transform)\n",
    "    test_dataset = datasets.CIFAR10('./data', train=False, download=True, transform=transform)\n",
    "\n",
    "    #Clear downloading message.\n",
    "    clear_output()\n",
    "    \n",
    "    # Split dataset into training set and validation set.\n",
    "    train_dataset, val_dataset = random_split(train_dataset, (45000, 5000))\n",
    "    \n",
    "    print(\"Image Shape: {}\".format(train_dataset[0][0].numpy().shape), end = '\\n\\n')\n",
    "    print(\"Training Set:   {} samples\".format(len(train_dataset)))\n",
    "    print(\"Validation Set:   {} samples\".format(len(val_dataset)))\n",
    "    print(\"Test Set:       {} samples\".format(len(test_dataset)))\n",
    "    \n",
    "    if torch.cuda.is_available():\n",
    "        BATCH_SIZE = 2048\n",
    "    else:\n",
    "        BATCH_SIZE = 32\n",
    "\n",
    "    # Create iterator.\n",
    "    train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "    test_loader = DataLoader(test_dataset, batch_size=10000, shuffle=True)\n",
    "    \n",
    "    # Delete the data/ folder.\n",
    "    shutil.rmtree('./data')\n",
    "    \n",
    "    return train_loader, val_loader, test_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 109,
     "referenced_widgets": [
      "adcdd49c5a24491d8f794e1b81274cb4",
      "93cb66d8aa8747708b72efd7543780b1",
      "330d0be50f5d40e2abc5385bf160bc7c",
      "8de8b13220b1415baaead8f77bfa3f30",
      "9cefaaf210b44353a284b90edd96867a",
      "cc8509ed5b894ae08c5ccdb91509d739",
      "126282012a1c4279b5cc6989929738cc",
      "8e3b615db3a7440290515e40c3dd017d"
     ]
    },
    "colab_type": "code",
    "id": "kmJhiFP3fYt8",
    "outputId": "d6fe816f-3451-4fad-f545-ae1e38f59567"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image Shape: (3, 32, 32)\n",
      "\n",
      "Training Set:   45000 samples\n",
      "Validation Set:   5000 samples\n",
      "Test Set:       10000 samples\n"
     ]
    }
   ],
   "source": [
    "train_loader, val_loader, test_loader = load_cifar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "B4KHh2jYfzbw"
   },
   "source": [
    "## b) Architecture build"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "jeM4Ev_vfDPq"
   },
   "outputs": [],
   "source": [
    "class LambdaLayer(nn.Module):\n",
    "    \n",
    "    def __init__(self, lambd):\n",
    "        super(LambdaLayer, self).__init__()\n",
    "        self.lambd = lambd\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.lambd(x)\n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    \n",
    "    def __init__(self, in_channels, out_channels, stride=1, option='A'):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        \n",
    "        self.features = nn.Sequential(OrderedDict([\n",
    "            ('conv1', nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)),\n",
    "            ('bn1', nn.BatchNorm2d(out_channels)),\n",
    "            ('act1', nn.ReLU()),\n",
    "            ('conv2', nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)),\n",
    "            ('bn2', nn.BatchNorm2d(out_channels))\n",
    "        ]))\n",
    "\n",
    "        self.shortcut = nn.Sequential()\n",
    "        \n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            if option == 'A':\n",
    "                pad = out_channels//4\n",
    "                self.shortcut = LambdaLayer(lambda x:\n",
    "                            F.pad(x[:, :, ::2, ::2], (0,0, 0,0, pad,pad, 0,0)))\n",
    "            if option == 'B':\n",
    "                self.shortcut = nn.Sequential(OrderedDict([\n",
    "                    ('s_conv1', nn.Conv2d(in_channels, 2*out_channels, kernel_size=1, stride=stride, padding=0, bias=False)),\n",
    "                    ('s_bn1', nn.BatchNorm2d(2*out_channels))\n",
    "                ]))\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LgugsfTHfDP4"
   },
   "outputs": [],
   "source": [
    "class ResNet(nn.Module):\n",
    "    \"\"\"\n",
    "        ResNet architecture for CIFAR-10.\n",
    "    \"\"\"\n",
    "    def __init__(self, block_type, num_blocks):\n",
    "        super(ResNet, self).__init__()\n",
    "        \n",
    "        self.in_channels = 16\n",
    "        \n",
    "        self.conv0 = nn.Conv2d(3, 16, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn0 = nn.BatchNorm2d(16)\n",
    "        self.block1 = self.__build_layer(block_type, 16, num_blocks[0], mismatch_stride=1)\n",
    "        self.block2 = self.__build_layer(block_type, 32, num_blocks[1], mismatch_stride=2)\n",
    "        self.block3 = self.__build_layer(block_type, 64, num_blocks[2], mismatch_stride=2)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1,1))\n",
    "        self.linear = nn.Linear(64, 10)\n",
    "    \n",
    "    def __build_layer(self, block_type, out_channels, num_blocks, mismatch_stride):\n",
    "        strides = [mismatch_stride] + [1]*(num_blocks-1)\n",
    "        layers = []\n",
    "        for stride in strides:\n",
    "            layers.append(block_type(self.in_channels, out_channels, stride))\n",
    "            self.in_channels = out_channels\n",
    "        return nn.Sequential(*layers)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn0(self.conv0(x)))\n",
    "        out = self.block1(out)\n",
    "        out = self.block2(out)        \n",
    "        out = self.block3(out)\n",
    "        out = self.avgpool(out)\n",
    "        out = torch.flatten(out, 1)\n",
    "        out = self.linear(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "ItbvSI6OfDQG"
   },
   "outputs": [],
   "source": [
    "def ResNet56():\n",
    "    return ResNet(block_type=ConvBlock, num_blocks=[9,9,9])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "colab_type": "code",
    "id": "Kd3x1j1DfDQW",
    "outputId": "3398ccfd-f8f2-4c7d-bed7-ebd4301e8a99"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 16, 32, 32]             432\n",
      "       BatchNorm2d-2           [-1, 16, 32, 32]              32\n",
      "            Conv2d-3           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-4           [-1, 16, 32, 32]              32\n",
      "              ReLU-5           [-1, 16, 32, 32]               0\n",
      "            Conv2d-6           [-1, 16, 32, 32]           2,304\n",
      "       BatchNorm2d-7           [-1, 16, 32, 32]              32\n",
      "         ConvBlock-8           [-1, 16, 32, 32]               0\n",
      "            Conv2d-9           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-10           [-1, 16, 32, 32]              32\n",
      "             ReLU-11           [-1, 16, 32, 32]               0\n",
      "           Conv2d-12           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-13           [-1, 16, 32, 32]              32\n",
      "        ConvBlock-14           [-1, 16, 32, 32]               0\n",
      "           Conv2d-15           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-16           [-1, 16, 32, 32]              32\n",
      "             ReLU-17           [-1, 16, 32, 32]               0\n",
      "           Conv2d-18           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-19           [-1, 16, 32, 32]              32\n",
      "        ConvBlock-20           [-1, 16, 32, 32]               0\n",
      "           Conv2d-21           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-22           [-1, 16, 32, 32]              32\n",
      "             ReLU-23           [-1, 16, 32, 32]               0\n",
      "           Conv2d-24           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-25           [-1, 16, 32, 32]              32\n",
      "        ConvBlock-26           [-1, 16, 32, 32]               0\n",
      "           Conv2d-27           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-28           [-1, 16, 32, 32]              32\n",
      "             ReLU-29           [-1, 16, 32, 32]               0\n",
      "           Conv2d-30           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-31           [-1, 16, 32, 32]              32\n",
      "        ConvBlock-32           [-1, 16, 32, 32]               0\n",
      "           Conv2d-33           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-34           [-1, 16, 32, 32]              32\n",
      "             ReLU-35           [-1, 16, 32, 32]               0\n",
      "           Conv2d-36           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-37           [-1, 16, 32, 32]              32\n",
      "        ConvBlock-38           [-1, 16, 32, 32]               0\n",
      "           Conv2d-39           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-40           [-1, 16, 32, 32]              32\n",
      "             ReLU-41           [-1, 16, 32, 32]               0\n",
      "           Conv2d-42           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-43           [-1, 16, 32, 32]              32\n",
      "        ConvBlock-44           [-1, 16, 32, 32]               0\n",
      "           Conv2d-45           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-46           [-1, 16, 32, 32]              32\n",
      "             ReLU-47           [-1, 16, 32, 32]               0\n",
      "           Conv2d-48           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-49           [-1, 16, 32, 32]              32\n",
      "        ConvBlock-50           [-1, 16, 32, 32]               0\n",
      "           Conv2d-51           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-52           [-1, 16, 32, 32]              32\n",
      "             ReLU-53           [-1, 16, 32, 32]               0\n",
      "           Conv2d-54           [-1, 16, 32, 32]           2,304\n",
      "      BatchNorm2d-55           [-1, 16, 32, 32]              32\n",
      "        ConvBlock-56           [-1, 16, 32, 32]               0\n",
      "           Conv2d-57           [-1, 32, 16, 16]           4,608\n",
      "      BatchNorm2d-58           [-1, 32, 16, 16]              64\n",
      "             ReLU-59           [-1, 32, 16, 16]               0\n",
      "           Conv2d-60           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-61           [-1, 32, 16, 16]              64\n",
      "      LambdaLayer-62           [-1, 32, 16, 16]               0\n",
      "        ConvBlock-63           [-1, 32, 16, 16]               0\n",
      "           Conv2d-64           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-65           [-1, 32, 16, 16]              64\n",
      "             ReLU-66           [-1, 32, 16, 16]               0\n",
      "           Conv2d-67           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-68           [-1, 32, 16, 16]              64\n",
      "        ConvBlock-69           [-1, 32, 16, 16]               0\n",
      "           Conv2d-70           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-71           [-1, 32, 16, 16]              64\n",
      "             ReLU-72           [-1, 32, 16, 16]               0\n",
      "           Conv2d-73           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-74           [-1, 32, 16, 16]              64\n",
      "        ConvBlock-75           [-1, 32, 16, 16]               0\n",
      "           Conv2d-76           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-77           [-1, 32, 16, 16]              64\n",
      "             ReLU-78           [-1, 32, 16, 16]               0\n",
      "           Conv2d-79           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-80           [-1, 32, 16, 16]              64\n",
      "        ConvBlock-81           [-1, 32, 16, 16]               0\n",
      "           Conv2d-82           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-83           [-1, 32, 16, 16]              64\n",
      "             ReLU-84           [-1, 32, 16, 16]               0\n",
      "           Conv2d-85           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-86           [-1, 32, 16, 16]              64\n",
      "        ConvBlock-87           [-1, 32, 16, 16]               0\n",
      "           Conv2d-88           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-89           [-1, 32, 16, 16]              64\n",
      "             ReLU-90           [-1, 32, 16, 16]               0\n",
      "           Conv2d-91           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-92           [-1, 32, 16, 16]              64\n",
      "        ConvBlock-93           [-1, 32, 16, 16]               0\n",
      "           Conv2d-94           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-95           [-1, 32, 16, 16]              64\n",
      "             ReLU-96           [-1, 32, 16, 16]               0\n",
      "           Conv2d-97           [-1, 32, 16, 16]           9,216\n",
      "      BatchNorm2d-98           [-1, 32, 16, 16]              64\n",
      "        ConvBlock-99           [-1, 32, 16, 16]               0\n",
      "          Conv2d-100           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-101           [-1, 32, 16, 16]              64\n",
      "            ReLU-102           [-1, 32, 16, 16]               0\n",
      "          Conv2d-103           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-104           [-1, 32, 16, 16]              64\n",
      "       ConvBlock-105           [-1, 32, 16, 16]               0\n",
      "          Conv2d-106           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-107           [-1, 32, 16, 16]              64\n",
      "            ReLU-108           [-1, 32, 16, 16]               0\n",
      "          Conv2d-109           [-1, 32, 16, 16]           9,216\n",
      "     BatchNorm2d-110           [-1, 32, 16, 16]              64\n",
      "       ConvBlock-111           [-1, 32, 16, 16]               0\n",
      "          Conv2d-112             [-1, 64, 8, 8]          18,432\n",
      "     BatchNorm2d-113             [-1, 64, 8, 8]             128\n",
      "            ReLU-114             [-1, 64, 8, 8]               0\n",
      "          Conv2d-115             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-116             [-1, 64, 8, 8]             128\n",
      "     LambdaLayer-117             [-1, 64, 8, 8]               0\n",
      "       ConvBlock-118             [-1, 64, 8, 8]               0\n",
      "          Conv2d-119             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-120             [-1, 64, 8, 8]             128\n",
      "            ReLU-121             [-1, 64, 8, 8]               0\n",
      "          Conv2d-122             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-123             [-1, 64, 8, 8]             128\n",
      "       ConvBlock-124             [-1, 64, 8, 8]               0\n",
      "          Conv2d-125             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-126             [-1, 64, 8, 8]             128\n",
      "            ReLU-127             [-1, 64, 8, 8]               0\n",
      "          Conv2d-128             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-129             [-1, 64, 8, 8]             128\n",
      "       ConvBlock-130             [-1, 64, 8, 8]               0\n",
      "          Conv2d-131             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-132             [-1, 64, 8, 8]             128\n",
      "            ReLU-133             [-1, 64, 8, 8]               0\n",
      "          Conv2d-134             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-135             [-1, 64, 8, 8]             128\n",
      "       ConvBlock-136             [-1, 64, 8, 8]               0\n",
      "          Conv2d-137             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-138             [-1, 64, 8, 8]             128\n",
      "            ReLU-139             [-1, 64, 8, 8]               0\n",
      "          Conv2d-140             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-141             [-1, 64, 8, 8]             128\n",
      "       ConvBlock-142             [-1, 64, 8, 8]               0\n",
      "          Conv2d-143             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-144             [-1, 64, 8, 8]             128\n",
      "            ReLU-145             [-1, 64, 8, 8]               0\n",
      "          Conv2d-146             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-147             [-1, 64, 8, 8]             128\n",
      "       ConvBlock-148             [-1, 64, 8, 8]               0\n",
      "          Conv2d-149             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-150             [-1, 64, 8, 8]             128\n",
      "            ReLU-151             [-1, 64, 8, 8]               0\n",
      "          Conv2d-152             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-153             [-1, 64, 8, 8]             128\n",
      "       ConvBlock-154             [-1, 64, 8, 8]               0\n",
      "          Conv2d-155             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-156             [-1, 64, 8, 8]             128\n",
      "            ReLU-157             [-1, 64, 8, 8]               0\n",
      "          Conv2d-158             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-159             [-1, 64, 8, 8]             128\n",
      "       ConvBlock-160             [-1, 64, 8, 8]               0\n",
      "          Conv2d-161             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-162             [-1, 64, 8, 8]             128\n",
      "            ReLU-163             [-1, 64, 8, 8]               0\n",
      "          Conv2d-164             [-1, 64, 8, 8]          36,864\n",
      "     BatchNorm2d-165             [-1, 64, 8, 8]             128\n",
      "       ConvBlock-166             [-1, 64, 8, 8]               0\n",
      "AdaptiveAvgPool2d-167             [-1, 64, 1, 1]               0\n",
      "          Linear-168                   [-1, 10]             650\n",
      "================================================================\n",
      "Total params: 853,018\n",
      "Trainable params: 853,018\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 12.16\n",
      "Params size (MB): 3.25\n",
      "Estimated Total Size (MB): 15.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "model = ResNet56()\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "model.to(device)\n",
    "summary(model, (3, 32, 32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "6qM6CeFFfDQh",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "rcpVpdesgdqE"
   },
   "source": [
    "## c) Training the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qIUPmJv0ga-O"
   },
   "outputs": [],
   "source": [
    "def train_model():\n",
    "    EPOCHS = 15\n",
    "    nb_examples = 45000\n",
    "    nb_val_examples = 5000\n",
    "    train_costs, val_costs = [], []\n",
    "    \n",
    "    #Training phase.\n",
    "    \n",
    "    for epoch in range(EPOCHS):\n",
    "\n",
    "        train_loss = 0\n",
    "        correct_train = 0\n",
    "        \n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            # Zero the parameter gradients.\n",
    "            optimizer.zero_grad()\n",
    "            \n",
    "            # Forward pass.\n",
    "            prediction = model(inputs)\n",
    "            \n",
    "            # Compute the loss.\n",
    "            loss = criterion(prediction, labels)\n",
    "          \n",
    "            # Backward pass.\n",
    "            loss.backward()\n",
    "            \n",
    "            # Optimize.\n",
    "            optimizer.step()\n",
    "            \n",
    "            # Compute training accuracy.\n",
    "            _, predicted = torch.max(prediction.data, 1)\n",
    "            correct_train += (predicted == labels).float().sum().item()\n",
    "            \n",
    "            # Compute batch loss.\n",
    "            train_loss += (loss.data.item() * inputs.shape[0])\n",
    "\n",
    "\n",
    "        train_loss /= nb_examples\n",
    "        train_costs.append(train_loss)\n",
    "        train_acc =  correct_train / nb_examples\n",
    "\n",
    "        val_loss = 0\n",
    "        correct_val = 0\n",
    "  \n",
    "        with torch.no_grad():\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "                # Forward pass.\n",
    "                prediction = model(inputs)\n",
    "\n",
    "                # Compute the loss.\n",
    "                loss = criterion(prediction, labels)\n",
    "\n",
    "                # Compute training accuracy.\n",
    "                _, predicted = torch.max(prediction.data, 1)\n",
    "                correct_val += (predicted == labels).float().sum().item()\n",
    "\n",
    "            # Compute batch loss.\n",
    "            val_loss += (loss.data.item() * inputs.shape[0])\n",
    "\n",
    "            val_loss /= nb_val_examples\n",
    "            val_costs.append(val_loss)\n",
    "            val_acc =  correct_val / nb_val_examples\n",
    "        \n",
    "        info = \"[Epoch {}/{}]: train-loss = {:0.6f} | train-acc = {:0.3f} | val-loss = {:0.6f} | val-acc = {:0.3f}\"\n",
    "        print(info.format(epoch+1, EPOCHS, train_loss, train_acc, val_loss, val_acc))\n",
    "        torch.save(model.state_dict(), 'save_weights/checkpoint_gpu_{}'.format(epoch + 1)) \n",
    "                                                                \n",
    "    torch.save(model.state_dict(), 'save_weights/resnet-56_weights_gpu')  \n",
    "        \n",
    "    return train_costs, val_costs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 311
    },
    "colab_type": "code",
    "id": "EtMARiQeir6f",
    "outputId": "a3b71448-2893-4c19-a9d1-bc2df8efccf4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Apr 29 10:56:13 2020       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 440.64.00    Driver Version: 418.67       CUDA Version: 10.1     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
      "| N/A   61C    P0    37W / 250W |  16275MiB / 16280MiB |      0%      Default |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                       GPU Memory |\n",
      "|  GPU       PID   Type   Process name                             Usage      |\n",
      "|=============================================================================|\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 293
    },
    "colab_type": "code",
    "id": "_k8Ece7vibGa",
    "outputId": "ee6a37d5-267d-4e76-8e0d-092ed7c4bed5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 1/15]: train-loss = 2.418560 | train-acc = 0.186 | val-loss = 0.345510 | val-acc = 0.260\n",
      "[Epoch 2/15]: train-loss = 1.814710 | train-acc = 0.318 | val-loss = 0.301081 | val-acc = 0.370\n",
      "[Epoch 3/15]: train-loss = 1.610937 | train-acc = 0.394 | val-loss = 0.274469 | val-acc = 0.431\n",
      "[Epoch 4/15]: train-loss = 1.430526 | train-acc = 0.465 | val-loss = 0.237520 | val-acc = 0.504\n",
      "[Epoch 5/15]: train-loss = 1.315914 | train-acc = 0.514 | val-loss = 0.223509 | val-acc = 0.553\n",
      "[Epoch 6/15]: train-loss = 1.204232 | train-acc = 0.560 | val-loss = 0.200776 | val-acc = 0.586\n",
      "[Epoch 7/15]: train-loss = 1.133270 | train-acc = 0.589 | val-loss = 0.196912 | val-acc = 0.612\n",
      "[Epoch 8/15]: train-loss = 1.051415 | train-acc = 0.621 | val-loss = 0.191916 | val-acc = 0.633\n",
      "[Epoch 9/15]: train-loss = 0.966809 | train-acc = 0.653 | val-loss = 0.166661 | val-acc = 0.670\n",
      "[Epoch 10/15]: train-loss = 0.902538 | train-acc = 0.678 | val-loss = 0.162810 | val-acc = 0.690\n",
      "[Epoch 11/15]: train-loss = 0.828471 | train-acc = 0.705 | val-loss = 0.147712 | val-acc = 0.713\n",
      "[Epoch 12/15]: train-loss = 0.762280 | train-acc = 0.729 | val-loss = 0.135717 | val-acc = 0.729\n",
      "[Epoch 13/15]: train-loss = 0.723422 | train-acc = 0.744 | val-loss = 0.142070 | val-acc = 0.739\n",
      "[Epoch 14/15]: train-loss = 0.656613 | train-acc = 0.766 | val-loss = 0.120628 | val-acc = 0.757\n",
      "[Epoch 15/15]: train-loss = 0.601020 | train-acc = 0.786 | val-loss = 0.123011 | val-acc = 0.757\n"
     ]
    }
   ],
   "source": [
    "train_costs, val_costs = train_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "Y3S2sOL5g1cF",
    "outputId": "ca311f8b-cbf3-4b43-c99b-5b4460638724"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 38,
     "metadata": {
      "tags": []
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Restore the model.\n",
    "model = ResNet56()\n",
    "model.load_state_dict(torch.load('save_weights/resnet-56_weights_gpu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "colab_type": "code",
    "id": "1pHQoZsMhaOB",
    "outputId": "a7699935-b23a-4324-f6a1-19f08d2279d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy: 0.7394\n"
     ]
    }
   ],
   "source": [
    "nb_test_examples = 10000\n",
    "correct = 0 \n",
    "\n",
    "model.eval().cuda()\n",
    "\n",
    "with  torch.no_grad():\n",
    "    for inputs, labels in test_loader:\n",
    "        inputs, labels = inputs.to(device), labels.to(device)\n",
    "        # Make predictions.\n",
    "        prediction = model(inputs)\n",
    "\n",
    "        # Retrieve predictions indexes.\n",
    "        _, predicted_class = torch.max(prediction.data, 1)\n",
    "\n",
    "        # Compute number of correct predictions.\n",
    "        correct += (predicted_class == labels).float().sum().item()\n",
    "\n",
    "test_accuracy = correct / nb_test_examples\n",
    "print('Test accuracy: {}'.format(test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "resnet_pytorch.ipynb",
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "pytorch"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "126282012a1c4279b5cc6989929738cc": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "330d0be50f5d40e2abc5385bf160bc7c": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "IntProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "IntProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "info",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_cc8509ed5b894ae08c5ccdb91509d739",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_9cefaaf210b44353a284b90edd96867a",
      "value": 1
     }
    },
    "8de8b13220b1415baaead8f77bfa3f30": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_8e3b615db3a7440290515e40c3dd017d",
      "placeholder": "â€‹",
      "style": "IPY_MODEL_126282012a1c4279b5cc6989929738cc",
      "value": " 170500096/? [00:20&lt;00:00, 76351689.40it/s]"
     }
    },
    "8e3b615db3a7440290515e40c3dd017d": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "93cb66d8aa8747708b72efd7543780b1": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "9cefaaf210b44353a284b90edd96867a": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": "initial"
     }
    },
    "adcdd49c5a24491d8f794e1b81274cb4": {
     "model_module": "@jupyter-widgets/controls",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_330d0be50f5d40e2abc5385bf160bc7c",
       "IPY_MODEL_8de8b13220b1415baaead8f77bfa3f30"
      ],
      "layout": "IPY_MODEL_93cb66d8aa8747708b72efd7543780b1"
     }
    },
    "cc8509ed5b894ae08c5ccdb91509d739": {
     "model_module": "@jupyter-widgets/base",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
